output: default
streamtags: []
groups: {}
asyncFuncTimeout: 1000
functions:
  - id: serde
    filter: "true"
    conf:
      mode: extract
      type: json
      srcField: _raw
  - id: code
    filter: user.message
    disabled: false
    conf:
      maxNumOfIterations: 5000
      activeLogSampleRate: 1
      useUniqueLogChannel: true
      code: |-
        // Cribl Stream Code Function: AI Conversation Analytics, Cost Tracking & Optimization
        // Analyzes conversation quality, calculates costs, and provides optimization insights

        // ===== PARSE JSON EVENT =====
        let eventData = {};
        let parseSuccess = true;
        try {
          if (typeof __e._raw === 'string') {
            eventData = JSON.parse(__e._raw);
          }
        } catch (e) {
          debug('Failed to parse _raw: ' + e.message);
          parseSuccess = false;
          __e['_parse_error'] = true;
          __e['_error_message'] = e.message;
        }

        // Only process if parsing succeeded
        if (parseSuccess) {

          // ===== CONFIGURATION =====
          // Cost per 1K tokens for different models (in USD)
        const MODEL_COSTS = {
          // OpenAI Models (Current as of Nov 2025)
          'gpt-4': { input: 0.03, output: 0.06 },
          'gpt-4-turbo': { input: 0.01, output: 0.03 },
          'gpt-3.5-turbo': { input: 0.0005, output: 0.0015 },
          'gpt-3.5-turbo-16k': { input: 0.003, output: 0.004 },
          
          // Anthropic Models (Updated to Claude 4/4.5 - Nov 2025)
          'claude-opus-4.1': { input: 0.015, output: 0.075 },
          'claude-sonnet-4.5': { input: 0.003, output: 0.015 },
          'claude-sonnet-4': { input: 0.003, output: 0.015 },
          'claude-haiku-4.5': { input: 0.0008, output: 0.004 },
          'claude-haiku-3.5': { input: 0.0008, output: 0.004 },
          
          // Legacy Claude 3 models (deprecated but may still be in use)
          'claude-3-opus': { input: 0.015, output: 0.075 },
          'claude-3-sonnet': { input: 0.003, output: 0.015 },
          'claude-3-haiku': { input: 0.00025, output: 0.00125 }, // Old pricing
          'claude-2.1': { input: 0.008, output: 0.024 },
          
          // Open Source Models (infrastructure cost estimates)
          'llama2:7b': { input: 0.0001, output: 0.0001 },
          'llama2:13b': { input: 0.0002, output: 0.0002 },
          'llama2:70b': { input: 0.0007, output: 0.0007 },
          'mixtral-8x7b': { input: 0.0003, output: 0.0003 },
          
          // Default fallback
          'default': { input: 0.001, output: 0.001 }
        };

          // Intent patterns for categorization
          const INTENT_PATTERNS = {
            'support': /help|issue|problem|error|broken|fix|not working|trouble|support/i,
            'sales': /buy|purchase|price|cost|plan|subscription|upgrade|trial/i,
            'technical': /api|integration|code|implement|technical|documentation|sdk/i,
            'general_info': /what is|how does|explain|tell me about|information/i,
            'feedback': /feedback|suggestion|improve|love|hate|good|bad/i,
            'billing': /invoice|payment|charge|refund|billing|credit card/i,
            'account': /account|login|password|email|profile|settings/i,
            'feature_request': /feature|would be nice|wish|could you add|request/i
          };

          // ===== TOKEN ESTIMATION =====
          function estimateTokens(text) {
            if (!text) return 0;
            // More accurate token estimation
            // Average English word is ~1.3 tokens, account for punctuation
            const words = text.trim().split(/\s+/).length;
            const punctuation = (text.match(/[.,!?;:]/g) || []).length;
            return Math.ceil(words * 1.3 + punctuation * 0.3);
          }

          const userMessage = (eventData.user && eventData.user.message) || '';
          const assistantMessage = (eventData.assistant && eventData.assistant.message) || '';
          const userTokens = estimateTokens(userMessage);
          const assistantTokens = estimateTokens(assistantMessage);

          // ===== COST CALCULATION =====
          const model = eventData.model || 'default';
          const costs = MODEL_COSTS[model] || MODEL_COSTS['default'];

          const inputCost = (userTokens / 1000) * costs.input;
          const outputCost = (assistantTokens / 1000) * costs.output;
          const totalCost = inputCost + outputCost;

          // Calculate hourly/daily projections
          const requestTime = eventData.request_time || 1; // seconds
          const requestsPerHour = 3600 / Math.max(requestTime, 1);
          const projectedHourlyCost = totalCost * requestsPerHour;
          const projectedDailyCost = projectedHourlyCost * 24;

          // ===== CONVERSATION QUALITY ANALYSIS =====

          // 1. Response Relevance Score (simple keyword overlap)
          const userWords = new Set(userMessage.toLowerCase().split(/\s+/));
          const assistantWords = new Set(assistantMessage.toLowerCase().split(/\s+/));
          const commonWords = [...userWords].filter(word => assistantWords.has(word));
          const relevanceScore = Math.min((commonWords.length / Math.max(userWords.size, 1)) * 100, 100);

          // 2. Response Length Ratio
          const lengthRatio = assistantMessage.length / Math.max(userMessage.length, 1);
          const lengthScore = lengthRatio < 0.5 ? 'too_short' : 
                             lengthRatio > 5 ? 'too_long' : 'balanced';

          // 3. Conversation Efficiency
          const totalTokens = userTokens + assistantTokens;
          const efficiencyScore = totalTokens < 100 ? 'highly_efficient' :
                                 totalTokens < 500 ? 'efficient' :
                                 totalTokens < 1000 ? 'moderate' : 'verbose';

          // 4. Response Time Performance
          const responseTimeMs = (eventData.request_time || 0) * 1000;
          const performanceRating = responseTimeMs < 1000 ? 'excellent' :
                                   responseTimeMs < 3000 ? 'good' :
                                   responseTimeMs < 5000 ? 'acceptable' : 'slow';

          // ===== INTENT DETECTION =====
          let detectedIntent = 'uncategorized';
          let intentConfidence = 0;

          for (const [intent, pattern] of Object.entries(INTENT_PATTERNS)) {
            if (pattern.test(userMessage)) {
              detectedIntent = intent;
              // Simple confidence based on pattern match strength
              const matches = userMessage.match(pattern) || [];
              intentConfidence = Math.min(matches.length * 25, 100);
              break;
            }
          }

          // ===== OPTIMIZATION RECOMMENDATIONS =====
          const optimizations = [];

          // Model optimization
          if (totalCost > 0.01 && model.includes('gpt-4')) {
            optimizations.push({
              type: 'model_downgrade',
              recommendation: 'Consider using gpt-3.5-turbo for this query type',
              potential_savings: `$${(totalCost * 0.9).toFixed(4)} per request`
            });
          }

          // Token optimization
          if (assistantTokens > 500) {
            optimizations.push({
              type: 'response_length',
              recommendation: 'Response may be unnecessarily verbose',
              current_tokens: assistantTokens,
              suggested_tokens: 200
            });
          }

          // Caching opportunity
          if (detectedIntent === 'general_info' || detectedIntent === 'support') {
            optimizations.push({
              type: 'caching_opportunity',
              recommendation: 'This appears to be a common query that could be cached',
              intent: detectedIntent,
              cache_hit_potential: 'high'
            });
          }

          // Streaming optimization
          if (!eventData.streaming && responseTimeMs > 2000) {
            optimizations.push({
              type: 'enable_streaming',
              recommendation: 'Enable streaming for better perceived performance',
              current_wait: `${responseTimeMs}ms`,
              improved_ttfb: '~500ms'
            });
          }

          // ===== CONVERSATION PATTERN ANALYSIS =====
          const conversationPatterns = {
            is_greeting: /^(hi|hello|hey|good morning|good afternoon)/i.test(userMessage.toLowerCase()),
            is_farewell: /(bye|goodbye|thanks|thank you|see you)/i.test(userMessage.toLowerCase()),
            has_question: /\?|^(what|when|where|why|how|can you|could you|would you)/i.test(userMessage),
            is_command: /^(show|list|find|search|create|delete|update)/i.test(userMessage.toLowerCase()),
            sentiment: userMessage.includes('!') ? 'excited' : 
                      /please|sorry|excuse/i.test(userMessage) ? 'polite' :
                      /hate|angry|frustrated|terrible/i.test(userMessage) ? 'negative' : 'neutral'
          };

          // ===== USER BEHAVIOR INSIGHTS =====
          const userBehavior = {
            message_complexity: userTokens < 10 ? 'simple' : userTokens < 30 ? 'moderate' : 'complex',
            likely_experience: conversationPatterns.is_greeting ? 'new_user' : 
                              detectedIntent === 'technical' ? 'developer' :
                              detectedIntent === 'sales' ? 'potential_customer' : 'regular_user',
            engagement_level: lengthRatio > 2 ? 'high' : lengthRatio > 0.5 ? 'medium' : 'low'
          };

          // ===== ADVANCED ANALYTICS =====
          
          // 1. Language Detection (simple heuristic)
          const languagePatterns = {
            spanish: /\b(hola|gracias|por favor|ayuda|cómo|qué|dónde)\b/i,
            french: /\b(bonjour|merci|s'il vous plaît|comment|où|quoi)\b/i,
            german: /\b(hallo|danke|bitte|hilfe|wie|was|wo)\b/i,
            portuguese: /\b(olá|obrigado|por favor|ajuda|como|onde)\b/i,
            chinese: /[\u4e00-\u9fa5]/,
            japanese: /[\u3040-\u309f\u30a0-\u30ff]/,
            korean: /[\uac00-\ud7af]/,
            arabic: /[\u0600-\u06ff]/
          };

          let detectedLanguage = 'english';
          for (const [lang, pattern] of Object.entries(languagePatterns)) {
            if (pattern.test(userMessage)) {
              detectedLanguage = lang;
              break;
            }
          }

          // 2. Sentiment Analysis (enhanced)
          const sentimentAnalysis = {
            positive_indicators: (userMessage.match(/\b(great|excellent|wonderful|amazing|perfect|love|thank|appreciate)\b/gi) || []).length,
            negative_indicators: (userMessage.match(/\b(terrible|awful|hate|angry|frustrated|disappointed|useless|bad)\b/gi) || []).length,
            urgency_indicators: (userMessage.match(/\b(urgent|asap|immediately|now|emergency|critical)\b/gi) || []).length,
            confusion_indicators: (userMessage.match(/\b(confused|don't understand|unclear|what do you mean|lost)\b/gi) || []).length
          };

          const sentimentScore = sentimentAnalysis.positive_indicators - sentimentAnalysis.negative_indicators;
          const overallSentiment = sentimentScore > 1 ? 'positive' : 
                                  sentimentScore < -1 ? 'negative' : 'neutral';

          // 3. Conversation Complexity Score
          const complexityFactors = {
            technical_terms: (userMessage.match(/\b(API|SDK|integration|backend|frontend|database|authentication|deployment)\b/gi) || []).length,
            multi_part_question: (userMessage.match(/\?/g) || []).length > 1,
            numbered_lists: /\b(1\.|2\.|first|second|third)\b/i.test(userMessage),
            code_snippets: /[{}\[\]();=<>]/.test(userMessage),
            long_form: userMessage.length > 500
          };

          const complexityScore = Object.values(complexityFactors).filter(Boolean).length;
          const complexityLevel = complexityScore === 0 ? 'basic' :
                                 complexityScore <= 2 ? 'moderate' : 'complex';

          // 4. Response Quality Scoring (enhanced)
          const qualityFactors = {
            addressed_question: conversationPatterns.has_question && assistantMessage.includes('?') ? -10 : 10,
            appropriate_length: lengthScore === 'balanced' ? 20 : 0,
            technical_accuracy: detectedIntent === 'technical' && assistantTokens > 100 ? 15 : 0,
            personalization: assistantMessage.match(/\b(you|your)\b/gi) ? 10 : 0,
            actionable_response: assistantMessage.match(/\b(try|click|go to|follow|check)\b/gi) ? 15 : 0,
            empathy_shown: overallSentiment === 'negative' && assistantMessage.match(/\b(sorry|understand|apologize|help)\b/gi) ? 20 : 0
          };

          const responseQualityScore = Object.values(qualityFactors).reduce((a, b) => a + b, 0);

          // 5. Topic Extraction (simple keyword extraction)
          const stopWords = new Set(['the', 'is', 'at', 'which', 'on', 'a', 'an', 'and', 'or', 'but', 'in', 'with', 'to', 'for', 'of', 'as', 'by', 'that', 'this', 'it', 'from', 'be', 'are', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'i', 'you', 'he', 'she', 'we', 'they', 'me', 'him', 'her', 'us', 'them']);
          const words = userMessage.toLowerCase().split(/\s+/);
          const topicWords = words.filter(word => 
            word.length > 3 && 
            !stopWords.has(word) && 
            !/^\d+$/.test(word)
          );
          const topTopics = topicWords.slice(0, 5);

          // 6. Error Detection
          const errorIndicators = {
            api_error: eventData.status && eventData.status >= 400,
            timeout_error: responseTimeMs > 30000,
            empty_response: !assistantMessage || assistantMessage.trim().length === 0,
            fallback_response: assistantMessage.match(/\b(I don't understand|I'm not sure|Could you rephrase)\b/i)
          };

          const hasError = Object.values(errorIndicators).some(Boolean);
          const errorType = Object.entries(errorIndicators).filter(([_, value]) => value).map(([key, _]) => key);

          // 7. Conversation Outcome Prediction
          const successIndicators = {
            thanked: userMessage.match(/\b(thank|thanks|appreciate|helpful|perfect)\b/i),
            question_answered: conversationPatterns.has_question && !assistantMessage.includes('?'),
            positive_sentiment: overallSentiment === 'positive',
            no_confusion: sentimentAnalysis.confusion_indicators === 0
          };

          const successScore = Object.values(successIndicators).filter(Boolean).length;
          const predictedOutcome = successScore >= 3 ? 'successful' : 
                                  successScore >= 1 ? 'partial_success' : 
                                  hasError ? 'failed' : 'uncertain';

          // 8. Token Efficiency Analysis
          const tokenEfficiency = {
            compression_ratio: userTokens > 0 ? assistantTokens / userTokens : 0,
            cost_per_outcome: totalCost / (successScore + 1),
            wasted_tokens: hasError ? assistantTokens : 0,
            optimal_response_length: userTokens * 2.5, // Rule of thumb
            length_variance: Math.abs(assistantTokens - (userTokens * 2.5))
          };

          // 9. Real-time Alert Conditions
          const alerts = [];
          
          if (totalCost > 0.05) {
            alerts.push({
              type: 'high_cost',
              severity: 'warning',
              message: `High cost interaction: ${totalCost.toFixed(4)}`,
              threshold: 0.05
            });
          }
          
          if (sentimentAnalysis.urgency_indicators > 0 && responseTimeMs > 5000) {
            alerts.push({
              type: 'urgent_slow_response',
              severity: 'critical',
              message: 'Urgent request with slow response time',
              response_time: responseTimeMs
            });
          }
          
          if (overallSentiment === 'negative' && predictedOutcome !== 'successful') {
            alerts.push({
              type: 'negative_experience',
              severity: 'high',
              message: 'Negative sentiment with unsuccessful outcome',
              action: 'Review conversation for improvement'
            });
          }

          // 10. Model Performance Metrics
          const modelPerformance = {
            response_speed: responseTimeMs < 1000 ? 'fast' : responseTimeMs < 3000 ? 'normal' : 'slow',
            token_generation_rate: assistantTokens / (requestTime || 1),
            cost_efficiency: (responseQualityScore / Math.max(totalCost * 1000, 0.001)).toFixed(2),
            error_rate: hasError ? 1 : 0
          };

          // ===== ADD ALL ANALYTICS TO EVENT =====

          // Cost Analytics
          __e['_cost_analysis'] = {
            tokens: {
              input: userTokens,
              output: assistantTokens,
              total: totalTokens
            },
            cost_usd: {
              input: parseFloat(inputCost.toFixed(6)),
              output: parseFloat(outputCost.toFixed(6)),
              total: parseFloat(totalCost.toFixed(6)),
              per_token: parseFloat((totalCost / totalTokens).toFixed(8))
            },
            projections: {
              hourly: parseFloat(projectedHourlyCost.toFixed(4)),
              daily: parseFloat(projectedDailyCost.toFixed(2)),
              monthly: parseFloat((projectedDailyCost * 30).toFixed(2))
            },
            model_tier: costs.output > 0.01 ? 'premium' : costs.output > 0.001 ? 'standard' : 'economy'
          };

          // Quality Metrics
          __e['_quality_metrics'] = {
            relevance_score: Math.round(relevanceScore),
            length_assessment: lengthScore,
            efficiency_rating: efficiencyScore,
            performance_rating: performanceRating,
            response_time_ms: responseTimeMs,
            tokens_per_second: totalTokens / Math.max(eventData.request_time || 1, 1)
          };

          // Intent and Behavior
          __e['_conversation_intelligence'] = {
            detected_intent: detectedIntent,
            intent_confidence: intentConfidence,
            conversation_patterns: conversationPatterns,
            user_behavior: userBehavior,
            detected_language: detectedLanguage,
            complexity_level: complexityLevel,
            topic_keywords: topTopics
          };

          // Enhanced Sentiment Analysis
          __e['_sentiment_analysis'] = {
            overall: overallSentiment,
            score: sentimentScore,
            indicators: sentimentAnalysis,
            urgency_level: sentimentAnalysis.urgency_indicators > 0 ? 'urgent' : 'normal',
            confusion_detected: sentimentAnalysis.confusion_indicators > 0
          };

          // Response Quality
          __e['_response_quality'] = {
            score: responseQualityScore,
            max_score: 100,
            quality_factors: qualityFactors,
            grade: responseQualityScore >= 80 ? 'A' :
                   responseQualityScore >= 60 ? 'B' :
                   responseQualityScore >= 40 ? 'C' : 'D'
          };

          // Error Tracking
          if (hasError) {
            __e['_error_detection'] = {
              has_error: true,
              error_types: errorType,
              error_details: errorIndicators
            };
          }

          // Conversation Outcome
          __e['_outcome_prediction'] = {
            predicted_outcome: predictedOutcome,
            success_indicators: successIndicators,
            success_score: successScore,
            confidence: successScore > 2 ? 'high' : successScore > 0 ? 'medium' : 'low'
          };

          // Token Efficiency
          __e['_token_efficiency'] = tokenEfficiency;

          // Model Performance
          __e['_model_performance'] = modelPerformance;

          // Real-time Alerts
          if (alerts.length > 0) {
            __e['_alerts'] = alerts;
            __e['_has_alerts'] = true;
            
            // Add alert tags for routing
            __e.tags = __e.tags || [];
            alerts.forEach(alert => {
              __e.tags.push(`alert_${alert.type}`);
            });
          }

          // Optimization Recommendations
          if (optimizations.length > 0) {
            __e['_optimization_opportunities'] = optimizations;
            __e['_has_optimizations'] = true;
          }

          // Session-level Aggregation Helper - Enhanced
          __e['_aggregation_keys'] = {
            model: model,
            intent: detectedIntent,
            efficiency: efficiencyScore,
            cost_bucket: totalCost < 0.001 ? 'micro' : totalCost < 0.01 ? 'small' : totalCost < 0.1 ? 'medium' : 'large',
            hour_of_day: new Date(eventData.timestamp || Date.now()).getHours(),
            language: detectedLanguage,
            sentiment: overallSentiment,
            outcome: predictedOutcome,
            quality_grade: __e['_response_quality'].grade,
            complexity: complexityLevel,
            has_errors: hasError
          };

          // Performance Anomalies
          if (responseTimeMs > 5000 || totalCost > 0.1 || assistantTokens > 1000) {
            __e['_anomaly_flags'] = {
              high_latency: responseTimeMs > 5000,
              high_cost: totalCost > 0.1,
              excessive_tokens: assistantTokens > 1000,
              severity: 'investigate'
            };
            
            __e.tags = __e.tags || [];
            __e.tags.push('performance_anomaly');
          }

          // Add conversation value score (0-100) - Enhanced calculation
          const valueScore = (
            (relevanceScore * 0.2) +
            (lengthScore === 'balanced' ? 15 : 5) +
            (efficiencyScore === 'efficient' || efficiencyScore === 'highly_efficient' ? 15 : 5) +
            (performanceRating === 'excellent' || performanceRating === 'good' ? 15 : 5) +
            (responseQualityScore * 0.3) +
            (predictedOutcome === 'successful' ? 15 : predictedOutcome === 'partial_success' ? 8 : 0)
          );

          __e['_conversation_value_score'] = Math.round(Math.min(valueScore, 100));

          // ROI Estimation
          const estimatedUserValue = detectedIntent === 'sales' ? 100 :
                                    detectedIntent === 'support' ? 50 :
                                    detectedIntent === 'technical' ? 75 : 25;

          __e['_roi_analysis'] = {
            estimated_value_usd: estimatedUserValue,
            cost_usd: totalCost,
            roi_ratio: parseFloat((estimatedUserValue / Math.max(totalCost, 0.001)).toFixed(2)),
            profitable: estimatedUserValue > totalCost * 10
          };

          // Copy original event data
          Object.assign(__e, eventData);

          // Generate conversation summary for easy logging
          __e['_conversation_summary'] = `${detectedIntent.toUpperCase()} | ${model} | ${overallSentiment} sentiment | ${predictedOutcome} outcome | ${totalCost.toFixed(4)} | ${totalTokens} tokens | Grade: ${__e['_response_quality'].grade}`;

          // Add processing metadata
          __e['_processing_metadata'] = {
            function_version: '2.0',
            processed_at: new Date().toISOString(),
            processing_time_ms: Date.now() - (eventData._time || Date.now())
          };

          // Debug output - Enhanced
          debug(`AI Analytics: ${model} | Cost: ${totalCost.toFixed(6)} | Intent: ${detectedIntent} | Sentiment: ${overallSentiment} | Outcome: ${predictedOutcome} | Quality: ${__e['_response_quality'].grade} | Value: ${__e['_conversation_value_score']}`);
          
          if (alerts.length > 0) {
            debug(`ALERTS: ${alerts.map(a => `${a.type}(${a.severity})`).join(', ')}`);
          }

        } // End of parseSuccess check

        // ===== USAGE NOTES =====
        /*
        This enhanced function provides comprehensive AI conversation analytics:

        1. COST TRACKING:
           - Per-request cost calculation
           - Hourly/daily/monthly projections
           - Model tier classification

        2. QUALITY ANALYSIS:
           - Relevance scoring
           - Response length assessment
           - Efficiency ratings
           - Performance metrics
           - Response quality grading (A-D)

        3. INTENT DETECTION:
           - Automatic categorization (support, sales, technical, etc.)
           - Confidence scoring
           - User behavior insights
           - Topic keyword extraction

        4. SENTIMENT ANALYSIS:
           - Positive/negative/neutral classification
           - Urgency detection
           - Confusion indicators
           - Detailed sentiment indicators

        5. LANGUAGE DETECTION:
           - Multi-language support
           - Automatic language identification

        6. CONVERSATION COMPLEXITY:
           - Technical term detection
           - Multi-part question identification
           - Code snippet detection
           - Complexity scoring

        7. ERROR TRACKING:
           - API error detection
           - Timeout monitoring
           - Empty response detection
           - Fallback response identification

        8. OUTCOME PREDICTION:
           - Success probability
           - Success indicators tracking
           - Confidence levels

        9. TOKEN EFFICIENCY:
           - Compression ratios
           - Cost per outcome
           - Wasted token tracking
           - Optimal length analysis

        10. REAL-TIME ALERTS:
            - High cost warnings
            - Urgent request monitoring
            - Negative experience detection
            - Custom alert routing

        11. OPTIMIZATION RECOMMENDATIONS:
            - Model downgrade opportunities
            - Response length optimization
            - Caching opportunities
            - Streaming suggestions

        12. VALUE METRICS:
            - Enhanced conversation value score (0-100)
            - ROI analysis
            - Profitability assessment

        KEY FIELDS FOR DASHBOARDS:
        - _cost_analysis.cost_usd.total - Track spending
        - _response_quality.grade - Monitor quality (A-D grades)
        - _sentiment_analysis.overall - User satisfaction
        - _outcome_prediction.predicted_outcome - Success tracking
        - _conversation_intelligence.detected_language - Language distribution
        - _alerts - Real-time issues requiring attention
        - _conversation_value_score - Overall effectiveness
        - _model_performance - Model comparison metrics

        AGGREGATION DIMENSIONS:
        - model, intent, sentiment, outcome, quality_grade
        - language, complexity, hour_of_day, has_errors
        - cost_bucket, efficiency

        ALERTING EXAMPLES:
        - High cost interactions > $0.05
        - Urgent requests with slow response
        - Negative sentiment with failed outcomes
        - Error patterns by model/intent

        Use these rich analytics to optimize your AI deployment!
        */
description: ""
